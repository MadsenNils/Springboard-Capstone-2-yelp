{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Capstone Project 2\n",
    "## Training models on the downsampled image set\n",
    "___\n",
    "\n",
    "There can be high variance in performance among instances of the same model trained on the same image set, due to the random initialization of weights. For this reason, multiple models were trained on the downsampled image set, and the best-performing model after 10 epochs was trained until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'cap2tools' from 'C:\\\\Users\\\\Nils\\\\Documents\\\\GitHub\\\\Springboard-Capstone-2-local-yelp\\\\cap2tools.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import importlib as imp\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "# custom module for capstone 2\n",
    "import cap2tools as c2t\n",
    "imp.reload(c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure GPU memory usage by tensorflow\n",
    "config = K.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "K.tensorflow_backend.set_session(K.tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5480 images belonging to 5 classes.\n",
      "Found 525 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# define paths to image directories\n",
    "photos_path = 'C:/Users/Nils/Documents/GitHub/Springboard-Capstone-2-local-yelp/downsampled/'\n",
    "train_path = photos_path + 'train'\n",
    "valid_path = photos_path + 'val'\n",
    "\n",
    "# create data generators\n",
    "train_batches, valid_batches = c2t.build_datagens(train_path, valid_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-21 00:49:43 - Started training models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46532, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46532 to 0.39715, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39715 to 0.37215, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37215 to 0.34887, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34887 to 0.32897, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32897 to 0.32777, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32777 to 0.31145, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31145 to 0.31048, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31048 to 0.30298, saving model to models/downsample_model_1.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30298 to 0.29883, saving model to models/downsample_model_1.h5\n",
      "2018-09-21 01:15:37 - Started training models/downsample_model_2.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51880, saving model to models/downsample_model_2.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51880 to 0.44571, saving model to models/downsample_model_2.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44571 to 0.39946, saving model to models/downsample_model_2.h5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39946\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39946 to 0.37665, saving model to models/downsample_model_2.h5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37665\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37665\n",
      "Epoch 00007: early stopping\n",
      "2018-09-21 01:33:41 - Started training models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44595, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44595 to 0.37613, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37613 to 0.35473, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35473 to 0.35056, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35056 to 0.32196, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32196\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32196 to 0.30439, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30439\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30439 to 0.30111, saving model to models/downsample_model_3.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30111 to 0.29917, saving model to models/downsample_model_3.h5\n",
      "2018-09-21 01:59:48 - Started training models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55349, saving model to models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55349 to 0.49491, saving model to models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.49491 to 0.45419, saving model to models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45419 to 0.40222, saving model to models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.40222\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.40222 to 0.38596, saving model to models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38596\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38596 to 0.37773, saving model to models/downsample_model_4.h5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37773\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37773 to 0.37193, saving model to models/downsample_model_4.h5\n",
      "2018-09-21 02:26:11 - Started training models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57453, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57453 to 0.46540, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46540 to 0.42519, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42519 to 0.41113, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41113 to 0.40248, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.40248 to 0.37852, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37852 to 0.37572, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37572 to 0.36994, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36994 to 0.36102, saving model to models/downsample_model_5.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36102 to 0.34901, saving model to models/downsample_model_5.h5\n",
      "2018-09-21 02:52:27 - Started training models/downsample_model_6.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37886, saving model to models/downsample_model_6.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37886 to 0.35094, saving model to models/downsample_model_6.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35094 to 0.34019, saving model to models/downsample_model_6.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34019 to 0.31792, saving model to models/downsample_model_6.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31792\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31792\n",
      "Epoch 00006: early stopping\n",
      "2018-09-21 03:08:04 - Started training models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61708, saving model to models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61708 to 0.53289, saving model to models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53289 to 0.52980, saving model to models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.52980 to 0.50053, saving model to models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50053 to 0.45659, saving model to models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45659 to 0.44169, saving model to models/downsample_model_7.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44169\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44169\n",
      "Epoch 00008: early stopping\n",
      "2018-09-21 03:29:03 - Started training models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52964, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52964 to 0.45302, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45302 to 0.40644, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40644 to 0.39885, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39885 to 0.38417, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38417 to 0.34452, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34452 to 0.34335, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34335 to 0.34185, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34185 to 0.32205, saving model to models/downsample_model_8.h5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32205\n",
      "2018-09-21 03:54:54 - Started training models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61635, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61635 to 0.51988, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51988 to 0.47062, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47062 to 0.43211, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.43211 to 0.41930, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41930\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41930 to 0.40582, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40582 to 0.39285, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39285 to 0.38585, saving model to models/downsample_model_9.h5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38585\n",
      "2018-09-21 04:20:42 - Started training models/downsample_model_10.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50460, saving model to models/downsample_model_10.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50460 to 0.37650, saving model to models/downsample_model_10.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37650 to 0.36725, saving model to models/downsample_model_10.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36725 to 0.33201, saving model to models/downsample_model_10.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33201 to 0.32967, saving model to models/downsample_model_10.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32967 to 0.32074, saving model to models/downsample_model_10.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32074\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32074\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "replicates = 10\n",
    "n_epochs = 10\n",
    "histories = dict()\n",
    "\n",
    "for i in range(1, replicates+1):\n",
    "    \n",
    "    # build model\n",
    "    model = c2t.build_VGG16(widths=(1000, 1250), \n",
    "                            new_weights=False, \n",
    "                            trainable=True, \n",
    "                            dropout1=0, \n",
    "                            dropout2=0.2)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0001, decay=0.1), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # define callbacks\n",
    "    filepath = 'models/downsample_model_{}.h5'.format(i)\n",
    "    saver = ModelCheckpoint(filepath,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True)\n",
    "\n",
    "    stopper = EarlyStopping(monitor='val_loss', \n",
    "                            patience=2, \n",
    "                            verbose=1)\n",
    "\n",
    "    datetime_now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('{} - Started training {}'.format(datetime_now, filepath))\n",
    "    \n",
    "    # train model\n",
    "    history = model.fit_generator(train_batches, \n",
    "                                  validation_data=valid_batches,\n",
    "                                  epochs=n_epochs, \n",
    "                                  verbose=0, \n",
    "                                  callbacks=[saver, stopper])\n",
    "    \n",
    "    histories[i] = history.history\n",
    "    \n",
    "    # clear memory\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image generator...\n",
      "Found 525 images belonging to 5 classes.\n",
      "Loading models/downsample_model_1.h5\n",
      "Evaluating models/downsample_model_1.h5\n",
      "Loading models/downsample_model_2.h5\n",
      "Evaluating models/downsample_model_2.h5\n",
      "Loading models/downsample_model_3.h5\n",
      "Evaluating models/downsample_model_3.h5\n",
      "Loading models/downsample_model_4.h5\n",
      "Evaluating models/downsample_model_4.h5\n",
      "Loading models/downsample_model_5.h5\n",
      "Evaluating models/downsample_model_5.h5\n",
      "Loading models/downsample_model_6.h5\n",
      "Evaluating models/downsample_model_6.h5\n",
      "Loading models/downsample_model_7.h5\n",
      "Evaluating models/downsample_model_7.h5\n",
      "Loading models/downsample_model_8.h5\n",
      "Evaluating models/downsample_model_8.h5\n",
      "Loading models/downsample_model_9.h5\n",
      "Evaluating models/downsample_model_9.h5\n",
      "Loading models/downsample_model_10.h5\n",
      "Evaluating models/downsample_model_10.h5\n",
      "Evaluation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on downsampled val set\n",
    "model_paths = dict()\n",
    "for i in range(1, replicates+1):\n",
    "    value = 'models/downsample_model_{}.h5'.format(str(i))\n",
    "    \n",
    "    model_paths[i] = value\n",
    "    \n",
    "model_metrics = c2t.eval_models(model_paths, valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'loss': 0.2988273965070645,\n",
       "  'acc': 0.8952380952380953,\n",
       "  'cm': [[89, 4, 5, 1, 6],\n",
       "   [5, 98, 0, 1, 1],\n",
       "   [5, 2, 89, 2, 7],\n",
       "   [0, 0, 0, 104, 1],\n",
       "   [0, 0, 14, 1, 90]],\n",
       "  'pcr': array([0.84761905, 0.93333333, 0.84761905, 0.99047619, 0.85714286]),\n",
       "  'mpcr': 0.8952380952380953},\n",
       " 2: {'loss': 0.376645097551823,\n",
       "  'acc': 0.8361904764175415,\n",
       "  'cm': [[79, 8, 12, 0, 6],\n",
       "   [9, 91, 1, 2, 2],\n",
       "   [8, 1, 79, 3, 14],\n",
       "   [1, 0, 0, 102, 2],\n",
       "   [1, 0, 15, 1, 88]],\n",
       "  'pcr': array([0.75238095, 0.86666667, 0.75238095, 0.97142857, 0.83809524]),\n",
       "  'mpcr': 0.8361904761904763},\n",
       " 3: {'loss': 0.2991715855140328,\n",
       "  'acc': 0.885714285941351,\n",
       "  'cm': [[87, 6, 8, 1, 3],\n",
       "   [3, 98, 0, 2, 2],\n",
       "   [6, 3, 81, 1, 14],\n",
       "   [1, 0, 0, 102, 2],\n",
       "   [0, 0, 8, 0, 97]],\n",
       "  'pcr': array([0.82857143, 0.93333333, 0.77142857, 0.97142857, 0.92380952]),\n",
       "  'mpcr': 0.8857142857142858},\n",
       " 4: {'loss': 0.37192804755035985,\n",
       "  'acc': 0.845714285941351,\n",
       "  'cm': [[77, 3, 19, 3, 3],\n",
       "   [2, 101, 0, 1, 1],\n",
       "   [6, 1, 71, 1, 26],\n",
       "   [1, 0, 0, 102, 2],\n",
       "   [0, 0, 12, 0, 93]],\n",
       "  'pcr': array([0.73333333, 0.96190476, 0.67619048, 0.97142857, 0.88571429]),\n",
       "  'mpcr': 0.8457142857142858},\n",
       " 5: {'loss': 0.3490073585074251,\n",
       "  'acc': 0.8742857145127796,\n",
       "  'cm': [[83, 1, 13, 3, 5],\n",
       "   [5, 97, 1, 1, 1],\n",
       "   [8, 2, 87, 0, 8],\n",
       "   [1, 0, 1, 102, 1],\n",
       "   [0, 0, 15, 0, 90]],\n",
       "  'pcr': array([0.79047619, 0.92380952, 0.82857143, 0.97142857, 0.85714286]),\n",
       "  'mpcr': 0.8742857142857143},\n",
       " 6: {'loss': 0.3179237864561202,\n",
       "  'acc': 0.872380952494485,\n",
       "  'cm': [[86, 6, 10, 1, 2],\n",
       "   [5, 94, 3, 1, 2],\n",
       "   [4, 2, 78, 1, 20],\n",
       "   [0, 0, 0, 103, 2],\n",
       "   [0, 0, 8, 0, 97]],\n",
       "  'pcr': array([0.81904762, 0.8952381 , 0.74285714, 0.98095238, 0.92380952]),\n",
       "  'mpcr': 0.8723809523809525},\n",
       " 7: {'loss': 0.4416859864861527,\n",
       "  'acc': 0.8247619048186711,\n",
       "  'cm': [[79, 11, 9, 2, 4],\n",
       "   [20, 84, 0, 1, 0],\n",
       "   [8, 2, 80, 3, 12],\n",
       "   [0, 0, 1, 102, 2],\n",
       "   [0, 0, 16, 1, 88]],\n",
       "  'pcr': array([0.75238095, 0.8       , 0.76190476, 0.97142857, 0.83809524]),\n",
       "  'mpcr': 0.8247619047619047},\n",
       " 8: {'loss': 0.3220455522636794,\n",
       "  'acc': 0.8838095239230565,\n",
       "  'cm': [[91, 1, 10, 1, 2],\n",
       "   [5, 95, 1, 4, 0],\n",
       "   [4, 1, 87, 2, 11],\n",
       "   [1, 0, 0, 103, 1],\n",
       "   [0, 0, 16, 1, 88]],\n",
       "  'pcr': array([0.86666667, 0.9047619 , 0.82857143, 0.98095238, 0.83809524]),\n",
       "  'mpcr': 0.8838095238095238},\n",
       " 9: {'loss': 0.38584933876793087,\n",
       "  'acc': 0.8742857142857143,\n",
       "  'cm': [[86, 3, 7, 2, 7],\n",
       "   [10, 91, 1, 2, 1],\n",
       "   [5, 0, 83, 2, 15],\n",
       "   [0, 0, 1, 104, 0],\n",
       "   [0, 0, 9, 1, 95]],\n",
       "  'pcr': array([0.81904762, 0.86666667, 0.79047619, 0.99047619, 0.9047619 ]),\n",
       "  'mpcr': 0.8742857142857143},\n",
       " 10: {'loss': 0.3207393296927746,\n",
       "  'acc': 0.872380952494485,\n",
       "  'cm': [[90, 3, 10, 1, 1],\n",
       "   [4, 99, 0, 1, 1],\n",
       "   [1, 1, 73, 3, 27],\n",
       "   [2, 0, 0, 102, 1],\n",
       "   [0, 0, 11, 0, 94]],\n",
       "  'pcr': array([0.85714286, 0.94285714, 0.6952381 , 0.97142857, 0.8952381 ]),\n",
       "  'mpcr': 0.8723809523809525}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "685/685 [==============================] - 156s 228ms/step - loss: 0.3869 - acc: 0.8491 - val_loss: 0.2918 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29180, saving model to models/downsample_model_1.h5\n",
      "Epoch 2/30\n",
      "685/685 [==============================] - 157s 229ms/step - loss: 0.3918 - acc: 0.8469 - val_loss: 0.2899 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29180 to 0.28985, saving model to models/downsample_model_1.h5\n",
      "Epoch 3/30\n",
      "685/685 [==============================] - 157s 229ms/step - loss: 0.3700 - acc: 0.8584 - val_loss: 0.2871 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28985 to 0.28706, saving model to models/downsample_model_1.h5\n",
      "Epoch 4/30\n",
      "685/685 [==============================] - 155s 226ms/step - loss: 0.3675 - acc: 0.8599 - val_loss: 0.2885 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28706\n",
      "Epoch 5/30\n",
      "685/685 [==============================] - 155s 226ms/step - loss: 0.3627 - acc: 0.8578 - val_loss: 0.2802 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28706 to 0.28016, saving model to models/downsample_model_1.h5\n",
      "Epoch 6/30\n",
      "685/685 [==============================] - 155s 226ms/step - loss: 0.3640 - acc: 0.8588 - val_loss: 0.2812 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28016\n",
      "Epoch 7/30\n",
      "685/685 [==============================] - 155s 226ms/step - loss: 0.3591 - acc: 0.8626 - val_loss: 0.2796 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.28016 to 0.27961, saving model to models/downsample_model_1.h5\n",
      "Epoch 8/30\n",
      "685/685 [==============================] - 158s 230ms/step - loss: 0.3657 - acc: 0.8582 - val_loss: 0.2772 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27961 to 0.27716, saving model to models/downsample_model_1.h5\n",
      "Epoch 9/30\n",
      "685/685 [==============================] - 159s 233ms/step - loss: 0.3468 - acc: 0.8677 - val_loss: 0.2779 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27716\n",
      "Epoch 10/30\n",
      "685/685 [==============================] - 159s 232ms/step - loss: 0.3557 - acc: 0.8650 - val_loss: 0.2736 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.27716 to 0.27362, saving model to models/downsample_model_1.h5\n",
      "Epoch 11/30\n",
      "685/685 [==============================] - 159s 232ms/step - loss: 0.3511 - acc: 0.8651 - val_loss: 0.2733 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27362 to 0.27326, saving model to models/downsample_model_1.h5\n",
      "Epoch 12/30\n",
      "685/685 [==============================] - 159s 232ms/step - loss: 0.3428 - acc: 0.8692 - val_loss: 0.2719 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27326 to 0.27189, saving model to models/downsample_model_1.h5\n",
      "Epoch 13/30\n",
      "685/685 [==============================] - 159s 232ms/step - loss: 0.3545 - acc: 0.8692 - val_loss: 0.2717 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27189 to 0.27173, saving model to models/downsample_model_1.h5\n",
      "Epoch 14/30\n",
      "685/685 [==============================] - 156s 228ms/step - loss: 0.3473 - acc: 0.8695 - val_loss: 0.2725 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27173\n",
      "Epoch 15/30\n",
      "685/685 [==============================] - 158s 231ms/step - loss: 0.3377 - acc: 0.8745 - val_loss: 0.2673 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27173 to 0.26735, saving model to models/downsample_model_1.h5\n",
      "Epoch 16/30\n",
      "685/685 [==============================] - 158s 231ms/step - loss: 0.3417 - acc: 0.8715 - val_loss: 0.2680 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26735\n",
      "Epoch 17/30\n",
      "685/685 [==============================] - 157s 230ms/step - loss: 0.3253 - acc: 0.8816 - val_loss: 0.2626 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26735 to 0.26261, saving model to models/downsample_model_1.h5\n",
      "Epoch 18/30\n",
      "685/685 [==============================] - 157s 228ms/step - loss: 0.3369 - acc: 0.8710 - val_loss: 0.2665 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26261\n",
      "Epoch 19/30\n",
      "685/685 [==============================] - 156s 228ms/step - loss: 0.3225 - acc: 0.8735 - val_loss: 0.2641 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26261\n",
      "Epoch 20/30\n",
      "685/685 [==============================] - 157s 229ms/step - loss: 0.3390 - acc: 0.8732 - val_loss: 0.2632 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26261\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16790"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model 1 until convergence\n",
    "model = load_model('models/downsample_model_1.h5')\n",
    "\n",
    "# define callbacks\n",
    "filepath = 'models/downsample_model_1.h5'\n",
    "saver = ModelCheckpoint(filepath,\n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True)\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_loss', \n",
    "                        patience=3, \n",
    "                        verbose=1)\n",
    "\n",
    "history = model.fit_generator(train_batches, \n",
    "                              validation_data=valid_batches,\n",
    "                              epochs=30, \n",
    "                              verbose=1, \n",
    "                              callbacks=[saver, stopper])\n",
    "\n",
    "# clear memory\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image generator...\n",
      "Found 20000 images belonging to 5 classes.\n",
      "Loading models/downsample_model_1.h5\n",
      "Evaluating models/downsample_model_1.h5\n",
      "Evaluation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on larger validation set\n",
    "model_paths = {'model': 'models/downsample_model_1.h5'}\n",
    "valid_path_large = 'H:/springboard/other_data/yelp/Photos/final_photos/val'\n",
    "model_metrics_large = c2t.eval_models(model_paths, valid_path_large)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  88.94%\n",
      "loss:  0.3005\n",
      "pcr:  [0.8722 0.9197 0.8053 1.     0.8646]\n",
      "mean pcr:  89.23%\n",
      "confusion matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[655, 17, 44, 7, 28],\n",
       " [697, 12179, 190, 70, 106],\n",
       " [92, 87, 3433, 44, 607],\n",
       " [0, 0, 0, 105, 0],\n",
       " [11, 2, 187, 22, 1417]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2t.print_eval(model_metrics_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
