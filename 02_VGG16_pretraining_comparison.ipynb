{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Capstone Project 2\n",
    "## Comparison of different convolutional weights\n",
    "___\n",
    "\n",
    "The first aspect of the model to investigate is whether the convolutional weights pretrained on the ImageNet dataset are useful for this dataset. To evaluate this, three model conditions were compared. In the first condition, the ImageNet weights were discarded and all weights were trained from scratch. In the second condition, the ImageNet weights were kept, but the model was not able to alter the weights of the convolutional layers during training. In the final condition, the ImageNet weights were kept, and the model was able to further train these weights to fine-tune the feature extraction for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'cap2tools' from 'C:\\\\Users\\\\Nils\\\\Documents\\\\GitHub\\\\Springboard-Capstone-2-local-yelp\\\\cap2tools.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from importlib import reload\n",
    "\n",
    "# custom module for capstone 2\n",
    "import cap2tools as c2t\n",
    "reload(c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure GPU memory usage by tensorflow\n",
    "config = K.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80\n",
    "K.tensorflow_backend.set_session(K.tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5480 images belonging to 5 classes.\n",
      "Found 525 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# define paths to image directories\n",
    "train_path = 'downsampled/train'\n",
    "valid_path = 'downsampled/val'\n",
    "\n",
    "# create image data generators to feed the model from image directories\n",
    "train_batches, valid_batches = c2t.build_datagens(train_path, valid_path, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30 15:00:04 - Started training models/vgg16_imagenet_baseline_1\n",
      "2018-09-30 15:10:00 - Started training models/vgg16_imagenet_baseline_2\n",
      "2018-09-30 15:20:01 - Started training models/vgg16_imagenet_baseline_3\n",
      "2018-09-30 15:29:56 - Started training models/vgg16_imagenet_trainable_1\n",
      "2018-09-30 15:54:33 - Started training models/vgg16_imagenet_trainable_2\n",
      "2018-09-30 16:19:21 - Started training models/vgg16_imagenet_trainable_3\n",
      "2018-09-30 16:44:18 - Started training models/vgg16_new_weights_1\n",
      "2018-09-30 17:09:09 - Started training models/vgg16_new_weights_2\n",
      "2018-09-30 17:33:55 - Started training models/vgg16_new_weights_3\n"
     ]
    }
   ],
   "source": [
    "widths = (500, 500) # 500 nodes in the FC layers\n",
    "replicates = 3 #run each condition in triplicate\n",
    "n_epochs = 10\n",
    "histories = dict()\n",
    "\n",
    "# baseline ImageNet weights\n",
    "condition = 'imagenet_baseline'\n",
    "histories[condition] = c2t.run_in_replicate(widths, condition, train_batches, valid_batches, \n",
    "                                            replicates=replicates, n_epochs=n_epochs, new_weights=False, \n",
    "                                            trainable=False)\n",
    "\n",
    "# trainable ImageNet weights\n",
    "condition = 'imagenet_trainable'\n",
    "histories[condition] = c2t.run_in_replicate(widths, condition, train_batches, valid_batches, \n",
    "                                            replicates=replicates, n_epochs=n_epochs, new_weights=False, \n",
    "                                            trainable=True)\n",
    "\n",
    "# new weights\n",
    "condition = 'new_weights'\n",
    "histories[condition] = c2t.run_in_replicate(widths, condition, train_batches, valid_batches, \n",
    "                                            replicates=replicates, n_epochs=n_epochs, new_weights=True, \n",
    "                                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5480 images belonging to 5 classes.\n",
      "Found 525 images belonging to 5 classes.\n",
      "2018-09-30 21:59:28 - Started training models/vgg16_imagenet_trainable_augment_1\n",
      "2018-09-30 22:24:37 - Started training models/vgg16_imagenet_trainable_augment_2\n",
      "2018-09-30 22:49:53 - Started training models/vgg16_imagenet_trainable_augment_3\n"
     ]
    }
   ],
   "source": [
    "widths = (500, 500)\n",
    "replicates = 3\n",
    "n_epochs = 10\n",
    "histories = dict()\n",
    "\n",
    "# create new data generators with image augmentation\n",
    "train_batches, valid_batches = c2t.build_datagens(train_path, valid_path, augment=True)\n",
    "\n",
    "# trainable ImageNet weights with image augmentation\n",
    "condition = 'imagenet_trainable_augment'\n",
    "histories[condition] = c2t.run_in_replicate(widths, condition, train_batches, valid_batches, \n",
    "                                            replicates=replicates, n_epochs=n_epochs, new_weights=False, \n",
    "                                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history\n",
    "hist_df = pd.DataFrame(histories).transpose()\n",
    "hist_df.to_json('VGG16_pretraining_comparison_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image generator...\n",
      "Found 525 images belonging to 5 classes.\n",
      "Loading models/vgg16_imagenet_baseline_1.h5\n",
      "Evaluating models/vgg16_imagenet_baseline_1.h5\n",
      "Loading models/vgg16_imagenet_baseline_2.h5\n",
      "Evaluating models/vgg16_imagenet_baseline_2.h5\n",
      "Loading models/vgg16_imagenet_baseline_3.h5\n",
      "Evaluating models/vgg16_imagenet_baseline_3.h5\n",
      "Loading models/vgg16_imagenet_trainable_1.h5\n",
      "Evaluating models/vgg16_imagenet_trainable_1.h5\n",
      "Loading models/vgg16_imagenet_trainable_2.h5\n",
      "Evaluating models/vgg16_imagenet_trainable_2.h5\n",
      "Loading models/vgg16_imagenet_trainable_3.h5\n",
      "Evaluating models/vgg16_imagenet_trainable_3.h5\n",
      "Loading models/vgg16_new_weights_1.h5\n",
      "Evaluating models/vgg16_new_weights_1.h5\n",
      "Loading models/vgg16_new_weights_2.h5\n",
      "Evaluating models/vgg16_new_weights_2.h5\n",
      "Loading models/vgg16_new_weights_3.h5\n",
      "Evaluating models/vgg16_new_weights_3.h5\n",
      "Loading models/vgg16_imagenet_trainable_augment_1.h5\n",
      "Evaluating models/vgg16_imagenet_trainable_augment_1.h5\n",
      "Loading models/vgg16_imagenet_trainable_augment_2.h5\n",
      "Evaluating models/vgg16_imagenet_trainable_augment_2.h5\n",
      "Loading models/vgg16_imagenet_trainable_augment_3.h5\n",
      "Evaluating models/vgg16_imagenet_trainable_augment_3.h5\n",
      "Evaluation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate trained models on validation dataset\n",
    "model_paths = {'ImageNet_baseline_1 - 1': 'models/vgg16_imagenet_baseline_1.h5', \n",
    "               'ImageNet_baseline_1 - 2': 'models/vgg16_imagenet_baseline_2.h5', \n",
    "               'ImageNet_baseline_1 - 3': 'models/vgg16_imagenet_baseline_3.h5', \n",
    "               'ImageNet_trainable_2 - 1': 'models/vgg16_imagenet_trainable_1.h5', \n",
    "               'ImageNet_trainable_2 - 2': 'models/vgg16_imagenet_trainable_2.h5', \n",
    "               'ImageNet_trainable_2 - 3': 'models/vgg16_imagenet_trainable_3.h5',\n",
    "               'New_weights_3 - 1': 'models/vgg16_new_weights_1.h5', \n",
    "               'New_weights_3 - 2': 'models/vgg16_new_weights_2.h5', \n",
    "               'New_weights_3 - 3': 'models/vgg16_new_weights_3.h5', \n",
    "               'ImageNet_augmented_4 - 1': 'models/vgg16_imagenet_trainable_augment_1.h5', \n",
    "               'ImageNet_augmented_4 - 2': 'models/vgg16_imagenet_trainable_augment_2.h5', \n",
    "               'ImageNet_augmente_4 - 3': 'models/vgg16_imagenet_trainable_augment_3.h5'}\n",
    "\n",
    "model_metrics = c2t.eval_models(model_paths, valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table of evaluation results\n",
    "table = c2t.eval_table(model_metrics, 'Condition', decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">loss</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mpcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.712</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc          loss          mpcr       \n",
       "             max   mean    min   mean    max   mean\n",
       "Condition                                          \n",
       "1.0        0.890  0.877  0.865  0.904  0.890  0.877\n",
       "2.0        0.874  0.872  0.357  0.375  0.874  0.872\n",
       "3.0        0.712  0.707  0.744  0.763  0.712  0.707\n",
       "4.0        0.863  0.854  0.353  0.381  0.863  0.854"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
