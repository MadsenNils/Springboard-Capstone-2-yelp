{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cap2tools' from 'C:\\\\Users\\\\Nils\\\\Documents\\\\GitHub\\\\Springboard-Capstone-2-local-yelp\\\\cap2tools.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import importlib as imp\n",
    "\n",
    "# custom module for capstone 2\n",
    "import cap2tools as c2t\n",
    "imp.reload(c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure GPU memory usage by tensorflow\n",
    "config = K.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80\n",
    "K.tensorflow_backend.set_session(K.tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220992 images belonging to 5 classes.\n",
      "Found 20000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# define paths to image directories\n",
    "photos_path = 'H:/springboard/other_data/yelp/Photos/final_photos/'\n",
    "train_path = photos_path + 'train'\n",
    "valid_path = photos_path + 'val'\n",
    "\n",
    "# build image generators to feed CNN\n",
    "train_batches, valid_batches = c2t.build_data_gens([train_path, valid_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = c2t.build_VGG16(width=800, \n",
    "                        new_weights=False, \n",
    "                        trainable=True, \n",
    "                        learning_rate=0.0001, \n",
    "                        dropout1=0, \n",
    "                        dropout2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27624/27624 [==============================] - 6054s 219ms/step - loss: 0.2532 - acc: 0.9151 - val_loss: 0.1973 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19728, saving model to final_model.h5\n",
      "Epoch 2/5\n",
      "27624/27624 [==============================] - 6021s 218ms/step - loss: 0.1957 - acc: 0.9319 - val_loss: 0.1827 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19728 to 0.18266, saving model to final_model.h5\n",
      "Epoch 3/5\n",
      "27624/27624 [==============================] - 6032s 218ms/step - loss: 0.1838 - acc: 0.9362 - val_loss: 0.1750 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.18266 to 0.17504, saving model to final_model.h5\n",
      "Epoch 4/5\n",
      "27624/27624 [==============================] - 6051s 219ms/step - loss: 0.1773 - acc: 0.9386 - val_loss: 0.1703 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17504 to 0.17035, saving model to final_model.h5\n",
      "Epoch 5/5\n",
      "27624/27624 [==============================] - 6029s 218ms/step - loss: 0.1727 - acc: 0.9400 - val_loss: 0.1671 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17035 to 0.16709, saving model to final_model.h5\n"
     ]
    }
   ],
   "source": [
    "# define callbacks\n",
    "filepath = 'models/large_model.h5'\n",
    "saver = ModelCheckpoint(filepath,\n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True)\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_loss', \n",
    "                        patience=2, \n",
    "                        verbose=1)\n",
    "\n",
    "# train model\n",
    "n_epochs = 10\n",
    "\n",
    "history = model.fit_generator(train_batches, \n",
    "                              validation_data=valid_batches,\n",
    "                              epochs=n_epochs, \n",
    "                              verbose=1, \n",
    "                              callbacks=[saver, stopper])\n",
    "\n",
    "# clear clutter from memory\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.19728139929915778,\n",
       "  0.18265847071080935,\n",
       "  0.1750368343205919,\n",
       "  0.17034693631324335,\n",
       "  0.16709436277593048],\n",
       " 'val_acc': [0.9304, 0.93635, 0.93875, 0.94065, 0.9418],\n",
       " 'loss': [0.25324471081322875,\n",
       "  0.19565610455911148,\n",
       "  0.18380035248226162,\n",
       "  0.17732823604556275,\n",
       "  0.1727181471390913],\n",
       " 'acc': [0.9151055241818709,\n",
       "  0.9318708369533739,\n",
       "  0.9361967854039965,\n",
       "  0.9386086374167391,\n",
       "  0.9399661526209093]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot model training history\n",
    "c2t.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image generator...\n",
      "Found 20000 images belonging to 5 classes.\n",
      "Loading model final_model.h5\n",
      "Evaluating model final_model.h5\n",
      "Evaluation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on validation set\n",
    "model_paths = {'model': filepath}\n",
    "model_metrics = c2t.eval_models(model_paths, valid_path)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67097701 0.98859316 0.92466063 0.47252747 0.75410834]\n",
      "0.7621733223609561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[467, 155, 63, 1, 10],\n",
       " [77, 13000, 66, 1, 6],\n",
       " [27, 122, 4087, 4, 180],\n",
       " [1, 13, 16, 43, 18],\n",
       " [6, 23, 373, 2, 1239]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2t.print_eval(model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
