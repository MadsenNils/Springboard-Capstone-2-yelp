{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Capstone Project 2\n",
    "\n",
    "## Image sampling\n",
    "___\n",
    "\n",
    "The full Yelp dataset contains more than 280,000 photos. To use the full dataset for the design of a deep learning algorithm would require a prohibitive amount of processing power and would lead to a long time between iterations. Instead, a subset of the photos will be sampled, and the algorithm will be designed to perform well on this subset. Then, for a final evaluation of the success of the algorithm, it will be trained once on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>photo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wRKYaVXTks43GVSI2awTQA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>IuXwafFH3fZlTyXA-poz0w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wRKYaVXTks43GVSI2awTQA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>vhnZ58_1shy9HNVdZgtMLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wRKYaVXTks43GVSI2awTQA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>j9ad7H2IBEzhfNCuJu4ukg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wRKYaVXTks43GVSI2awTQA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>du-5X44HccQ9Zo3pQPiFgQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wRKYaVXTks43GVSI2awTQA</td>\n",
       "      <td>The classic Farmer's Choice Breakfast has a li...</td>\n",
       "      <td>food</td>\n",
       "      <td>u7Tt1nvclYNoq3UOToP-GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                            caption  \\\n",
       "0  wRKYaVXTks43GVSI2awTQA                                                      \n",
       "1  wRKYaVXTks43GVSI2awTQA                                                      \n",
       "2  wRKYaVXTks43GVSI2awTQA                                                      \n",
       "3  wRKYaVXTks43GVSI2awTQA                                                      \n",
       "4  wRKYaVXTks43GVSI2awTQA  The classic Farmer's Choice Breakfast has a li...   \n",
       "\n",
       "  label                photo_id  \n",
       "0  food  IuXwafFH3fZlTyXA-poz0w  \n",
       "1  food  vhnZ58_1shy9HNVdZgtMLw  \n",
       "2  food  j9ad7H2IBEzhfNCuJu4ukg  \n",
       "3  food  du-5X44HccQ9Zo3pQPiFgQ  \n",
       "4  food  u7Tt1nvclYNoq3UOToP-GA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json into pandas dataframe\n",
    "all_images = pd.read_json('yelp_academic_dataset_photo.json', lines=True)\n",
    "all_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280992 entries, 0 to 280991\n",
      "Data columns (total 2 columns):\n",
      "photo_id    280992 non-null object\n",
      "label       280992 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.3+ MB\n",
      "None\n",
      "['food' 'drink' 'outside' 'inside' 'menu']\n"
     ]
    }
   ],
   "source": [
    "# trim dataframe\n",
    "all_images = all_images[['photo_id', 'label']]\n",
    "\n",
    "# ensure there are no missing data from label field (nan or empty strings)\n",
    "print(all_images.info())\n",
    "print(all_images['label'].unique())\n",
    "\n",
    "# ensure all photo IDs are unique\n",
    "assert all_images.photo_id.nunique() == len(all_images.photo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set photo_id as the index\n",
    "all_images.set_index('photo_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample out test image set\n",
    "test_images = all_images.sample(n=30000, replace=False, weights=None, random_state=12)\n",
    "test_images['set'] = 'test'\n",
    "\n",
    "# remove test images from consideration\n",
    "train_images = all_images[~all_images.index.isin(test_images.index)]\n",
    "\n",
    "# sample out validation image set\n",
    "val_images = train_images.sample(n=20000, replace=False, weights=None, random_state=34)\n",
    "val_images['set'] = 'val'\n",
    "\n",
    "# remaining images are training images\n",
    "train_images = train_images[~train_images.index.isin(val_images.index)]\n",
    "train_images['set'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    230992\n",
       "test      30000\n",
       "val       20000\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine sets back together\n",
    "final = pd.concat([test_images, val_images, train_images], axis=0)\n",
    "final['set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all photo IDs are unique\n",
    "assert final.index.nunique() == len(final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save photo dataframe as csv file\n",
    "final.to_csv('photo_labels_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images into new directories\n",
    "orig_dir = 'H:/springboard/other_data/yelp/Photos/yelp_academic_dataset_photos/'\n",
    "dest_dir = 'H:/springboard/other_data/yelp/Photos/final_photos/'\n",
    "\n",
    "for index, row in final.iterrows():\n",
    "    filepath = orig_dir + index + '.jpg'\n",
    "    filedest = dest_dir + row['set'] + '/' + row['label']\n",
    "    _ = shutil.copy(filepath, filedest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "___\n",
    "\n",
    "The model is not performing optimally due to class imbalance in the dataset. While performing at 99% accuracy on the highest representation class (food), the model's accuracy drops to an abysmal 47% on the least represented class (menu). One way to work around the presence of class imbalance in the dataset is to take a random sample of the more represented classes, to bring all the classes into balance with the least represented class. While this will greatly reduce the total amount of data that the model is trained on, the elimination of class imbalance may lead to the model performing better anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food       151588\n",
       "inside      50684\n",
       "outside     19138\n",
       "drink        8486\n",
       "menu         1096\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class imbalance in the training set\n",
    "train_images.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food       13242\n",
       "inside      4263\n",
       "outside     1639\n",
       "drink        751\n",
       "menu         105\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class imbalance in the validation set\n",
    "val_images.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all images of menu class\n",
    "menu_train = train_images[train_images.label == 'menu']\n",
    "train_n = len(menu_train.label)\n",
    "\n",
    "menu_val = val_images[val_images.label == 'menu']\n",
    "val_n = len(menu_val.label)\n",
    "\n",
    "# downsample other classes\n",
    "food_train = train_images[train_images.label == 'food'].sample(n=train_n, replace=False, random_state=12)\n",
    "food_val = val_images[val_images.label == 'food'].sample(n=val_n, replace=False, random_state=123)\n",
    "\n",
    "inside_train = train_images[train_images.label == 'inside'].sample(n=train_n, replace=False, random_state=23)\n",
    "inside_val = val_images[val_images.label == 'inside'].sample(n=val_n, replace=False, random_state=234)\n",
    "\n",
    "outside_train = train_images[train_images.label == 'outside'].sample(n=train_n, replace=False, random_state=34)\n",
    "outside_val = val_images[val_images.label == 'outside'].sample(n=val_n, replace=False, random_state=345)\n",
    "\n",
    "drink_train = train_images[train_images.label == 'drink'].sample(n=train_n, replace=False, random_state=45)\n",
    "drink_val = val_images[val_images.label == 'drink'].sample(n=val_n, replace=False, random_state=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all samples\n",
    "train = pd.concat([menu_train, food_train, inside_train, outside_train, drink_train], axis=0)\n",
    "val = pd.concat([menu_val, food_val, inside_val, outside_val, drink_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drink      1096\n",
      "inside     1096\n",
      "outside    1096\n",
      "menu       1096\n",
      "food       1096\n",
      "Name: label, dtype: int64\n",
      "menu       105\n",
      "drink      105\n",
      "outside    105\n",
      "inside     105\n",
      "food       105\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# classes are now balanced in the downsampled dataset\n",
    "print(train.label.value_counts())\n",
    "print(val.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    5480\n",
       "val       525\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframes\n",
    "train['set'] = 'train'\n",
    "val['set'] = 'val'\n",
    "downsampled = pd.concat([train, val], axis=0)\n",
    "downsampled.set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "downsampled.to_csv('photo_labels_downsampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images into new directories\n",
    "orig_dir = 'H:/springboard/other_data/yelp/Photos/yelp_academic_dataset_photos/'\n",
    "dest_dir = 'C:/Users/Nils/Documents/GitHub/Springboard-Capstone-2-local-yelp/downsampled/'\n",
    "\n",
    "for index, row in downsampled.iterrows():\n",
    "    filepath = orig_dir + index + '.jpg'\n",
    "    filedest = dest_dir + row['set'] + '/' + row['label']\n",
    "    _ = shutil.copy(filepath, filedest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
