{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'cap2tools' from 'C:\\\\Users\\\\Nils\\\\Documents\\\\GitHub\\\\Springboard-Capstone-2-local-yelp\\\\cap2tools.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from importlib import reload\n",
    "\n",
    "# custom module for capstone 2\n",
    "import cap2tools as c2t\n",
    "reload(c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure GPU memory usage by tensorflow\n",
    "config = K.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80\n",
    "K.tensorflow_backend.set_session(K.tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5480 images belonging to 5 classes.\n",
      "Found 525 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# define paths to image directories\n",
    "train_path = 'downsampled/train'\n",
    "valid_path = 'downsampled/val'\n",
    "\n",
    "# create data generators\n",
    "train_batches, valid_batches = c2t.build_datagens(train_path, valid_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-14 13:26:56 - Started training models/vgg16_width_200_1\n"
     ]
    }
   ],
   "source": [
    "# test different widths for model\n",
    "widths = [200, 400, 600, 800, 1000]\n",
    "replicates = 2\n",
    "n_epochs = 10\n",
    "\n",
    "histories = dict()\n",
    "\n",
    "for width in widths:\n",
    "    condition = 'width_{}'.format(str(width))\n",
    "    histories[width] = c2t.run_in_replicate(width, condition, train_batches, valid_batches, \n",
    "                                            replicates=replicates, n_epochs=n_epochs, new_weights=False, \n",
    "                                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history\n",
    "hist_df = pd.DataFrame(histories).transpose()\n",
    "hist_df.to_json('VGG16_width_comparison_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model comparison\n",
    "c2t.plot_metric('acc', hist_df)\n",
    "c2t.plot_metric('loss', hist_df)\n",
    "c2t.plot_metric('val_acc', hist_df)\n",
    "c2t.plot_metric('val_loss', hist_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
